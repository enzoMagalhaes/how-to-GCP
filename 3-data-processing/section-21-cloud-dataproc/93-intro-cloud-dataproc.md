
# Cloud DataProc

  - Managed Hadoop & Spark Services inside GCP

  - Lift/Shift Existing Hadoop/Spark based job

  - Cluster type
    * Standard (1 master, N workers)
    * Single node (1 master, 0 workers)
    * High Availability (3 masters, N workers)

  - worker node regular VM or Preemptible VM (Cost Reduction)

  - Job Supported:
    * Hadoop
    * SparkR
    * Spark
    * SparkSQL
    * Hive
    * Pig
    * PySpark

  - Demo
    * Spark
    * PySpark
    * Notebook instance
